<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.18">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="wkevin RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="wkevin Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="wkevin JSON Feed">
<link rel="stylesheet" href="/katex/katex.min.css"><title data-rh="true">LLM 概览 | wkevin</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://wkevin.github.io/blog/2023/04/25/llm.survey"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="LLM 概览 | wkevin"><meta data-rh="true" name="description" content="llm.survey"><meta data-rh="true" property="og:description" content="llm.survey"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-04-25T00:00:00.000Z"><meta data-rh="true" property="article:author" content="http://weibo.com/wkevin27"><meta data-rh="true" property="article:tag" content="llm,survey"><link data-rh="true" rel="icon" href="/img/logo.svg"><link data-rh="true" rel="canonical" href="https://wkevin.github.io/blog/2023/04/25/llm.survey"><link data-rh="true" rel="alternate" href="https://wkevin.github.io/blog/2023/04/25/llm.survey" hreflang="en"><link data-rh="true" rel="alternate" href="https://wkevin.github.io/blog/2023/04/25/llm.survey" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.941905f7.css">
<link rel="preload" href="/assets/js/runtime~main.173e6b64.js" as="script">
<link rel="preload" href="/assets/js/main.4a461576.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="wkevin Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.svg" alt="wkevin Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">wKevin</b></a><a class="navbar__item navbar__link" href="/docs/stack/">技术栈</a><a class="navbar__item navbar__link" href="/docs/project/industry/">业务场</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">博客</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/blog/tags">Tags</a><a class="navbar__item navbar__link" href="/blog/rss.xml">Feed</a><a href="https://github.com/wkevin" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_S7eR colorModeToggle_vKtC"><button class="clean-btn toggleButton_rCf9 toggleButtonDisabled_Pu9x" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">LLM 概览</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2023-04-25T00:00:00.000Z" itemprop="datePublished">April 25, 2023</time></div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="http://weibo.com/wkevin27" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="/img/avastar/angry.bird-l.jpg" alt="wKevin"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="http://weibo.com/wkevin27" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">wKevin</span></a></div><small class="avatar__subtitle" itemprop="description">一颗向上的水滴</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>我是从 3 月的 ChatGPT 爆发才开始关注大模型的，经过一番手忙脚乱的注册 openai 的 id、使用其 python sdk 后，这才开始转入对 LLM 的观察和学习上来。</p><p>2018 年学过 CNN、RNN 后除了在视觉上做了一些产品外，NLP 基本没接触，所以对 Transformer、ViT 都略过了，忽然被 ChatGPT 刺激了一下，才发现 Transformer 除了 NLP，也已经横扫 CV 了，效果超过 NN。那好吧，赶紧补课，把 LLM 学起来。</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="发展史">发展史<a class="hash-link" href="#发展史" title="Direct link to heading">​</a></h2><p>谢天谢地，有几篇 paper 已经准备好给我填鸭式教学了：</p><p><img loading="lazy" src="/assets/images/2023-05-10-18-17-46-f2197d1e561e4d4f67c689033bef0a30.png" width="1106" height="589" class="img_E7b_"></p><p><a href="https://arxiv.org/abs/2303.18223" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2303.18223</a> —— 首先是这篇一众国人联手写的，信息整理全面。挑了一些作为我后续关注的重点（重点关注国产、开源）：</p><ul><li>2018 OpenAI GPT</li><li>202103，THUDM（清华），GLM</li><li>202104，PLC（鹏程实验室）+华为，盘古</li><li>202105，OpenAI，CodeX</li><li>202205，THUNLP（OpenBMB），CPM</li><li>202302, Meta, LLaMA（羊驼），已经后续的 Alpaca（小羊驼）、Vicuna（野羊驼）</li><li>202303，THUDM（清华）,CodeGeeX</li></ul><blockquote><p>后续补充：</p></blockquote><ul><li>202305，MosaicML， MPT</li><li>202305， bigcode（Huggingface &amp; ServiceNow），StarCoder</li></ul><p>读完 paper，基本了解了 LLM 的发展历程，比如：</p><ul><li>Transformer 从 2017.12 Google 提出后，经过了 3 年左右的缓慢爬坡，LLM 并没有大量出现，直到 2020 年，因为算力的提升，2020.5 英伟达发布了 A100,单精度达到 19.5TFLOPS，助力了 LLM 开始狂飙。</li><li>ChatGPT 是 GPT-3 之后的 InstructGPT 改造而来的。</li><li>THUDM 和 THUNLP 分别是清华计算机学院和 NLP 学院的两个团队，分别打造 LLM。</li><li>Google 发布的 LLM 可谓是最多，但没能创造风口，有点遗憾。后来读到 2022.02 Google 的《LaMDA: Language models for dialog applications》（<a href="http://arxiv.org/abs/2201.08239%EF%BC%89%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2201.08239），可以看到</a> Google 诉苦良多，为了 Quality、Safety、and Groundedness，让 OpenAI 占了先机，气的很，哈哈。</li><li>了解到 LLM 考虑到本地 inference 受限，大多以是所有 WebAPI 作为使用接口（ChatGPT 就是这样）。</li><li>了解到各个模型根据语料库的不同，在不同领域表现不同，所以拿 GPT-3 与 AlphaCode 比谁生成的代码好就不厚道了，因为 GPT-3 的数据集里没有 Code。</li></ul><p><img loading="lazy" src="/assets/images/2023-05-10-18-32-51-3189742dc2adc8462a6e64f22d2cc393.png" width="1245" height="477" class="img_E7b_"></p><p>总之，很感谢作者们的这篇文章，让我有了个全貌的了解。</p><p>第 2 篇：<a href="https://arxiv.org/abs/2304.13712" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2304.13712</a> —— 这篇文章更学术一些，amazone 一众研究员撰写，开篇一幅图就爱了：</p><p><img loading="lazy" src="/assets/images/2023-05-10-18-36-37-e852f7f12310afe27e68c99b8039f4e0.png" width="2566" height="2071" class="img_E7b_"></p><p>它根据 Encoder、Decoder、Encoder&amp;Decoder 三个分支给 LLM 做了分类，当然这不是什么新分类法，Huggingface 中的文档 <a href="https://huggingface.co/docs/transformers/model_summary" target="_blank" rel="noopener noreferrer">The Transformer model family</a> 早就是这么分类的了，但这个图画的确实好，整理的很完整，我甚至打印出来，没遇到一个最近发布的新模型，还要定位、补充进去。</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="领域视角">领域视角<a class="hash-link" href="#领域视角" title="Direct link to heading">​</a></h2><p>最颠覆的我的，就是看到 ViT，看了 <a href="http://arxiv.org/abs/2010.11929" target="_blank" rel="noopener noreferrer">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a>，再听了李沐在 Bilibili 上解读 ViT 的视频后，更加对 Transformer 兴趣盎然，后来又进一步了解到凯明大神的 MAE，以及 Diffusion 扩散模型、DiTs……好多东西扑面而来，虽然我无法弄懂里面的所有原理，但尽可能的理解对于开发基于 LLM 的 APP 应该是有益的。</p><p>下面分别是 Transformer 模型在 NLP、视觉、Audio、多模态 四个领域的主流模型，图中并不是某某公司发布的 LLM，而是 LLM 的技术架构，分成四幅图很好的展示了四个应用领域（或场景）。</p><p><img loading="lazy" src="/assets/images/2023-05-10-18-52-37-d86a5dbba4dcfcad0efeb61adc70374e.png" width="1018" height="326" class="img_E7b_"></p><p><img loading="lazy" src="/assets/images/2023-05-10-18-51-58-f19eee2bee23385fce40e0655e1518dd.png" width="940" height="339" class="img_E7b_"></p><p><img loading="lazy" src="/assets/images/2023-05-10-18-52-54-23c1f2f6cb4f1860634de6246b9c1c61.png" width="1027" height="345" class="img_E7b_"></p><p><img loading="lazy" src="/assets/images/2023-05-10-18-53-10-1e7393c67bcdb7e04b61c6e374d34f5e.png" width="1023" height="350" class="img_E7b_"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="成本">成本<a class="hash-link" href="#成本" title="Direct link to heading">​</a></h2><p>大型语言模型在尺寸和成本上都在不断扩大。2019 年发布的 GPT-2 被认为是第一个大型语言模型，它有 1.5B（15 亿）个参数，训练成本估计为 5 万美元。仅仅三年后，540B 参数，预估花费 800 万美元的 Palm 就出来了。
2022 年末至今，在所有领域，大型语言和多模态模型都在变得更大、更贵。2023 年 4 月斯坦福发布的 《The State of AI in 2023》中显示：</p><p><img loading="lazy" src="/assets/images/2023-05-10-18-03-41-a0fa461504f2e7dd99e40c3a7f466d56.png" width="2000" height="1333" class="img_E7b_"></p><p>有些 LLM 还会在自己的网站上写明花费，比如清华 THUNLP 的 OpenBMB 社区的 CPM：43w，68 天 —— 你觉得这钱和这碳排放值不值？</p><p><img loading="lazy" src="/assets/images/2023-05-10-19-33-04-dd6cf4b84a8a2deadfd4722d5eda5b1e.png" width="993" height="507" class="img_E7b_"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="task">Task<a class="hash-link" href="#task" title="Direct link to heading">​</a></h2><p>LLM 能做什么？怎么分类？</p><p>可能很多人和我一样，从 ChatGPT 切入 LLM 后对它聊天之外的能力感觉不明显，但聊天是我们口语话的功能，并不是技术领域的 Task，比如聊天中可能需要总结一段话、预测下一句、填空、回答一个指定问题、翻译……这都是聊天，那专业的分类方式是什么，看这里：</p><p><a href="https://huggingface.co/docs/transformers/v4.29.0/en/main_classes/pipelines#transformers" target="_blank" rel="noopener noreferrer">transformers - pipeline</a></p><p>列了 27 个 Task</p><ul><li>audio<ul><li>&quot;audio-classification&quot;</li><li>&quot;automatic-speech-recognition&quot;</li><li>&quot;zero-shot-audio-classification&quot;</li></ul></li><li>cv<ul><li>分类<ul><li>&quot;image-classification&quot;</li><li>&quot;video-classification&quot;</li><li>&quot;zero-shot-image-classification&quot;</li></ul></li><li>物体检测<ul><li>&quot;object-detection&quot;</li><li>&quot;zero-shot-object-detection&quot;</li></ul></li><li>分割<ul><li>&quot;image-segmentation&quot;</li></ul></li><li>深度估算<ul><li>&quot;depth-estimation&quot;</li></ul></li></ul></li><li>nlp<ul><li>文本分类<ul><li>&quot;text-classification&quot; (alias &quot;sentiment-analysis&quot; available)</li><li>&quot;zero-shot-classification&quot;</li></ul></li><li>token 分类<ul><li>&quot;token-classification&quot;</li></ul></li><li>问答<ul><li>&quot;question-answering&quot;</li><li>&quot;table-question-answering&quot;</li></ul></li><li>总结<ul><li>&quot;summarization&quot;</li></ul></li><li>翻译<ul><li>&quot;translation&quot;</li><li>&quot;translation_xx_to_yy&quot;</li></ul></li><li>语言建模（生成）<ul><li>&quot;text2text-generation&quot;</li><li>&quot;text-generation&quot;</li><li>&quot;fill-mask&quot;</li><li>&quot;mask-generation&quot;</li><li>&quot;conversational&quot;</li></ul></li></ul></li><li>多模态<ul><li>&quot;document-question-answering&quot;</li><li>&quot;feature-extraction&quot;</li><li>&quot;image-to-text&quot;</li><li>&quot;visual-question-answering&quot;</li></ul></li></ul><p>先建立这些概念，这样当开发 LLM 的 API 时，就可以轻松地使用 SDK 中的各种 API 及其术语、概念。</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="playground">playground<a class="hash-link" href="#playground" title="Direct link to heading">​</a></h2><p>虽然已经出现了一些笔记本可运行的大模型，甚至浏览器可以运行的 LLM，但主流还是在有 GPU 的电脑、工作站上运行的模式，当然最好是薅一些 Data Center 的羊毛，比如:</p><ul><li><a href="https://huggingface.co/spaces" target="_blank" rel="noopener noreferrer">HuggingFace 上的 space</a> 可以用 hf 的算力，来运行一些 hf 的 model，各个 model 呈现的 UI 不一样，需要仔细挑选一下。</li><li><a href="https://platform.openai.com/playground" target="_blank" rel="noopener noreferrer">OpenAI playground</a>: OpenAI 为 ChatGPT（其实包括了 GPT 多个版本）开发的演练场，可以在里面玩一玩，对应学习 openai 的 python sdk 包是有帮助的。</li></ul></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/llm">llm</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/survey">survey</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/2023/05/17/vits"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">ViT ChatGPT 问答</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2023/04/10/openai.cookbook"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">OpenAI python SDK</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#发展史" class="table-of-contents__link toc-highlight">发展史</a></li><li><a href="#领域视角" class="table-of-contents__link toc-highlight">领域视角</a></li><li><a href="#成本" class="table-of-contents__link toc-highlight">成本</a></li><li><a href="#task" class="table-of-contents__link toc-highlight">Task</a></li><li><a href="#playground" class="table-of-contents__link toc-highlight">playground</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items"><li class="footer__item"><a href="http://weibo.com/wkevin27" target="_blank" rel="noopener noreferrer" class="footer__link-item">微博</a></li><li class="footer__item"><a href="https://twitter.com/wkevin27" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter</a></li><li class="footer__item"><a href="https://gitee.com/wkevin" target="_blank" rel="noopener noreferrer" class="footer__link-item">Gitee</a></li><li class="footer__item"><a href="https://blog.csdn.net/kevin881" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li></ul></div><div class="col footer__col"><div class="footer__title">Awesome</div><ul class="footer__items"><li class="footer__item"><a href="https://arxiv.org/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Arxiv</a></li><li class="footer__item"><a href="https://www.tianlangbooks.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">天浪书屋</a></li><li class="footer__item"><a href="https://yts.mx/" target="_blank" rel="noopener noreferrer" class="footer__link-item">YTS</a></li></ul></div><div class="col footer__col"><div class="footer__title">Collaborate</div><ul class="footer__items"><li class="footer__item"><a href="https://mubu.com/app" target="_blank" rel="noopener noreferrer" class="footer__link-item">幕布</a></li><li class="footer__item"><a href="https://shimo.im/" target="_blank" rel="noopener noreferrer" class="footer__link-item">石墨</a></li><li class="footer__item"><a href="https://www.feishu.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">飞书</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 wkevin, built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.173e6b64.js"></script>
<script src="/assets/js/main.4a461576.js"></script>
</body>
</html>